{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Colab Implementation of the Vesuvius Challenge Grand Prize Winning Solution**\n"
      ],
      "metadata": {
        "id": "ZXk_WJ8LkXgh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEc8XfVX2xDR"
      },
      "source": [
        " **Introduction**\n",
        "\n",
        "This notebook is a Colab implementation of the Vesuvius Challenge Grand Prize Winning solution by Youssef Nader, Luke Farritor, and Julian Schiliger ([here](https://github.com/younader/Vesuvius-Grandprize-Winner)).\n",
        "\n",
        "This fork of the model contains Pygosceles' significant training optimisations and speed improvements (15–20x+!) ([here]( https://github.com/StewartSethA/Vesuvius-Grandprize-Winner)).\n",
        "\n",
        "The inference script was improved by cody256c's contributions ([here]( https://github.com/cody256c/gp-winner-modified)). It also has a fix from O_D.\n",
        "\n",
        "The structure of this notebook was informed by Sean Johnson's (Bruniss') implementation of Youssef Nader's First Letters model ([here](https://colab.research.google.com/drive/1vvAmVas7ChFmX1xtNVYvJRtA_gsDnenv?usp=sharing)). It also contains a script from Bruniss' implementation to quickly download files to google drive.\n",
        "\n",
        "The intention of this notebook is to make running this model more accessible, especially for those who are not very familiar with machine learning.\n",
        "\n",
        "---\n",
        "\n",
        " **Training and Inference**\n",
        "\n",
        "\n",
        "This solution has two processes.\n",
        "\n",
        "The first process, [training](https://developers.google.com/machine-learning/glossary#training),  [models](https://developers.google.com/machine-learning/glossary#model) what is and isn't ink by parsing [labelled](https://developers.google.com/machine-learning/glossary#label), unrolled 'segments' of the Herculaneum papyri. The labels, 'maps' of where the ink is — or where we guess the ink is! — in the scrolls, train the model to identify ink. To produce the best results, multiple passes over the entire training set ([epochs](https://developers.google.com/machine-learning/glossary#epoch)) are performed. At the end of each epoch, the script generates a [checkpoint](https://developers.google.com/machine-learning/glossary#checkpoint). A segment is also used for [validation](https://developers.google.com/machine-learning/glossary#validation) to periodically evaluate the quality of the model.\n",
        "\n",
        "The second process, [inference](https://developers.google.com/machine-learning/glossary#inference), uses those checkpoints to produce [predictions](https://developers.google.com/machine-learning/glossary#prediction) of where the ink is in unlabelled segments. The prediction output is an image of the scroll segment (i.e. hopefully of the text).\n",
        "\n",
        "General introductions to machine learning can be found [here](https://developers.google.com/machine-learning/foundational-courses\n",
        ").\n",
        "\n",
        "---\n",
        "\n",
        " **Colab Requirements**\n",
        "\n",
        "*   ***Google Drive Storage Space:***\n",
        "\n",
        "    * *Training:* Space for the segments used to train the model (generally 10s of GB each) and checkpoints produced (generally hundreds of MB each).\n",
        "  \n",
        "     The data for the 'ink banner' segments and a single validation segment takes up around 350GB in total.      \n",
        "\n",
        "    * *Inference:* Space for the segement to be analysed (generally 10s of GB), checkpoint used (generally hundreds of MB), and inference results (generally 10s of MB).\n",
        "\n",
        "* ***Hardware:***\n",
        "\n",
        "    * This notebook was tested on a Colab Pro+ subscription, utilising an A100 (40GB) with 83.5GB system RAM. It is possible to execute inference successfully (albeit with extended run times) using lower tier Colab hardware, if the number of workers etc is adjusted. For training, the 83.5 GB system RAM available is a significant bottleneck.\n",
        "---\n",
        "\n",
        "\n",
        "**Local Hardware**\n",
        "\n",
        "It is possible to execute this notebook on your local hardware (Colab's instructions [here](https://research.google.com/colaboratory/local-runtimes.html)).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A. Initial Setup (Training and Inference)**"
      ],
      "metadata": {
        "id": "YJDM59dQj7rF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRTIkwmEwauP"
      },
      "source": [
        "**A.1. Mount Google Drive.**\n",
        "\n",
        "This allows files stored in google drive to be accessed by the model's scripts. (Click the square brackets below to run the command)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-_MmgRC2GCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9dd4411-8789-4c69-fbf9-d99e9c34f1c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W_YcpPwgUHm"
      },
      "source": [
        "**A.2.  Change directory to Google Drive.**\n",
        "\n",
        "This ensures the Github repository and any changes you make to the scripts will be saved, even after Colab is closed.                              "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxIy5qjngPDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ed1536-bf4e-4de2-d180-e00dcc1578ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive\n",
            "/content/gdrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd gdrive\n",
        "%cd MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3eHuMokwvDc"
      },
      "source": [
        "**A.3. Clone the repository from Github.**\n",
        "\n",
        "This creates a copy of the Github repository that can be executed by Colab.  \n",
        "This command only needs to be run once. If you would like to remove any of your modifications to the scripts, delete the repository from your google drive and run this command again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOfVjreuxcMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c1b7f6-6660-48e6-801f-4866ab55c1c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Vesuvius-Grandprize-Winner' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Bodillium/Vesuvius-Grandprize-Winner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV_DBFmMPocB"
      },
      "source": [
        "**A.4. Create the directories to be used.**\n",
        "\n",
        "This will not overwrite the directories if they already exist.\n",
        "\n",
        "***Scroll segments not listed:*** To create a directory for a different scroll segment, simply copy+paste the relevant line below, add it to the list, and replace the segment number (e.g. 20231005123336) with the number you want before running the command. The training and/or inference scripts will need to be adjusted accordingly (instructions below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uofzmi9SQGgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a46b501f-0ec7-49bc-ffae-9036df87dafd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/gdrive/Mydrive’: Operation not supported\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/checkpoints' # Where to put the checkpoints used in inference\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/inference_output' # Where the inference outputs (predictions) are saved\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/volume/segments/20231005123336/layers' # The segment on which inference is to be run\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20230702185753/layers' # The segments used to train the model\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20230929220926/layers'\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20231005123336/layers'\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20231007101619/layers'\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20231012184423/layers'\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20231016151002/layers'\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20231022170901/layers'\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20231031143852/layers'\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20231106155351/layers'\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20231210121321/layers'\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20231221180251/layers'\n",
        "!mkdir -p '/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/20230820203112/layers' # Current validation segment\n",
        "!mkdir -p '/content/gdrive/Mydrive/vesuvius_model/training/outputs' # Where the training outputs (checkpoints, etc) are saved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCOi45Ywx-EC"
      },
      "source": [
        "**A.5. Change directory to the repository directory.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-rWjszkxtGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c84777-1a91-497d-ec76-fba10d42bad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Vesuvius-Grandprize-Winner\n"
          ]
        }
      ],
      "source": [
        "%cd Vesuvius-Grandprize-Winner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BifJKt-RQpsj"
      },
      "source": [
        "**A.6. Download the layers of the segments into their respective folders.**\n",
        "\n",
        "The 'layers' folders of each segment you intend to load must be filled with their respective .tif files from the data server.\n",
        "\n",
        "For example, the folder /training/train_scrolls/20231005123336/layers must contain the layers 00–64.tif found [here](http://dl.ash2txt.org/full-scrolls/Scroll1.volpkg/paths/20231005123336/layers/) on the data server, to use this segment for training.\n",
        "\n",
        "*For training:* you'll need to download the layers into the numbered layers subfolders found in training/train_scrolls for both the segments of the model you're using and the 'validation' segment.\n",
        "\n",
        "*For inference:* you'll need to download they layers into the numbered layers subfolder of the segment you wish to use in volume/segments/.\n",
        "\n",
        "The following script (written by Bruniss) downloads these files directly into the correct folder on your google drive (much quicker than downloading them to your computer, then uploading to google drive).\n",
        "\n",
        "***Using the Script:***\n",
        "1. Navigate to the script *downloader.py* by clicking the 'folder' icon on the left-hand side of Colab and clicking through the filepath: /content/gdrive/MyDrive/Vesuvius-Grandprize-Winner/utilities/downloader.py . Double click to open the script.\n",
        "2. In **line 15** of the script, replace the word USERNAME and then the word PASSWORD with the username and password you receive after consenting to the [data agreement](https://docs.google.com/forms/d/e/1FAIpQLSf2lCOCwnO1xo0bc1QdlL0a034Uoe7zyjYBY2k33ZHslHE38Q/viewform?usp=send_form).\n",
        "3. In **line 8**, change the URL to the URL you wish to download the layers from (there should be a / at the end of the URL). This needs to be repeated for each set of layers you need to download.\n",
        "4. In **line 11**, change the directory to the location you wish to download the files to. The number of the file you download (e.g. 20231005123336) should match the number of the directory you are saving the files to (e.g. 20231005123336/layers).\n",
        "5. Run the script below! Repeat for each set of layers you need."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python utilities/downloader.py"
      ],
      "metadata": {
        "id": "N2mIVmvb5Qcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63fbf908-f757-4e9b-9fb9-de1ecd9f1251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 00.tif...\n",
            "Downloading 01.tif...\n",
            "Downloading 02.tif...\n",
            "Downloading 03.tif...\n",
            "Downloading 04.tif...\n",
            "Downloading 05.tif...\n",
            "Downloading 06.tif...\n",
            "Downloading 07.tif...\n",
            "Downloading 08.tif...\n",
            "Downloading 09.tif...\n",
            "Downloading 10.tif...\n",
            "Downloading 11.tif...\n",
            "Downloading 12.tif...\n",
            "Downloading 13.tif...\n",
            "Downloading 14.tif...\n",
            "Downloading 15.tif...\n",
            "Downloading 16.tif...\n",
            "Downloading 17.tif...\n",
            "Downloading 18.tif...\n",
            "Downloading 19.tif...\n",
            "Downloading 20.tif...\n",
            "Downloading 21.tif...\n",
            "Downloading 22.tif...\n",
            "Downloading 23.tif...\n",
            "Downloading 24.tif...\n",
            "Downloading 25.tif...\n",
            "Downloading 26.tif...\n",
            "Downloading 27.tif...\n",
            "Downloading 28.tif...\n",
            "Downloading 29.tif...\n",
            "Downloading 30.tif...\n",
            "Downloading 31.tif...\n",
            "Downloading 32.tif...\n",
            "Downloading 33.tif...\n",
            "Downloading 34.tif...\n",
            "Downloading 35.tif...\n",
            "Downloading 36.tif...\n",
            "Downloading 37.tif...\n",
            "Downloading 38.tif...\n",
            "Downloading 39.tif...\n",
            "Downloading 40.tif...\n",
            "Downloading 41.tif...\n",
            "Downloading 42.tif...\n",
            "Downloading 43.tif...\n",
            "Downloading 44.tif...\n",
            "Downloading 45.tif...\n",
            "Downloading 46.tif...\n",
            "Downloading 47.tif...\n",
            "Downloading 48.tif...\n",
            "Downloading 49.tif...\n",
            "Downloading 50.tif...\n",
            "Downloading 51.tif...\n",
            "Downloading 52.tif...\n",
            "Downloading 53.tif...\n",
            "Downloading 54.tif...\n",
            "Downloading 55.tif...\n",
            "Downloading 56.tif...\n",
            "Downloading 57.tif...\n",
            "Downloading 58.tif...\n",
            "Downloading 59.tif...\n",
            "Downloading 60.tif...\n",
            "Downloading 61.tif...\n",
            "Downloading 62.tif...\n",
            "Downloading 63.tif...\n",
            "Downloading 64.tif...\n",
            "Download completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A.7. Download the masks of the required segments into their respective folders.**\n",
        "\n",
        "As well a a layers folder, the numbered folders of each segment you load must contain its respective 'segment mask' file from the data server. This applies to both training and inference.\n",
        "\n",
        "For example, the folder /vesuvius_model/training/train_scrolls/20231005123336 must contain the file called 20231005123336_mask.png found [here](http://dl.ash2txt.org/full-scrolls/Scroll1.volpkg/paths/20231005123336/), to use this segment for training.\n",
        "\n",
        "Similarly, the folder /vesuvius_model/volume/segments/20231005123336 must contain the same mask as above to run inference on this segment.\n",
        "\n",
        "As the masks are very small, it  may be quicker to download them from the file server and upload them to your google drive directly, instead of using the previous script.\n"
      ],
      "metadata": {
        "id": "F50jFMpdtKFS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzxsLSQlVuAc"
      },
      "source": [
        "**A.8. Install the required dependencies.**\n",
        "\n",
        "This installs the software the scripts depend on to function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjHfydBoRP05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6366a542-5a37-4c6b-e395-c54017f69248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Vesuvius-Grandprize-Winner\n",
            "Collecting timm (from -r requirements.txt (line 1))\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting segmentation_models_pytorch (from -r requirements.txt (line 2))\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.3.1)\n",
            "Collecting wandb (from -r requirements.txt (line 4))\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning==2.0.9 (from -r requirements.txt (line 5))\n",
            "  Downloading pytorch_lightning-2.0.9-py3-none-any.whl (727 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.7/727.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting monai[einops] (from -r requirements.txt (line 6))\n",
            "  Downloading monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting warmup_scheduler (from -r requirements.txt (line 7))\n",
            "  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.7.1)\n",
            "Collecting timesformer-pytorch (from -r requirements.txt (line 10))\n",
            "  Downloading timesformer_pytorch-0.4.1-py3-none-any.whl (6.1 kB)\n",
            "Collecting typed-argument-parser (from -r requirements.txt (line 11))\n",
            "  Downloading typed-argument-parser-1.10.0.tar.gz (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (4.11.0)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 1)) (0.17.1+cu121)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 1)) (0.4.2)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch->-r requirements.txt (line 2))\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch->-r requirements.txt (line 2))\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm (from -r requirements.txt (line 1))\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch->-r requirements.txt (line 2)) (9.4.0)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch->-r requirements.txt (line 2))\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 3)) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 3)) (0.19.3)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 3)) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 3)) (4.9.0.80)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 4)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 4))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 4)) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 4))\n",
            "  Downloading sentry_sdk-1.45.0-py2.py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 4))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->-r requirements.txt (line 4))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 4)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 4)) (3.20.3)\n",
            "Collecting einops (from monai[einops]->-r requirements.txt (line 6))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 8)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 8)) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 9)) (3.1.2)\n",
            "Collecting typing-inspect>=0.7.1 (from typed-argument-parser->-r requirements.txt (line 11))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from typed-argument-parser->-r requirements.txt (line 11)) (0.16)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (3.9.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 4))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations->-r requirements.txt (line 3)) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (2024.2.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 3)) (3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 3)) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 3)) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 3)) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.7.1->typed-argument-parser->-r requirements.txt (line 11))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (4.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 4))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->-r requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning==2.0.9->-r requirements.txt (line 5)) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels, warmup_scheduler, typed-argument-parser\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=748925340bff0d6ccae7c4170f18caf92f7c3b3d20d62e34c4b7e97f50f63bc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=9bdb210c4b8bd6d5f9ce42968d03189bbc015503cdbf9f0cfe74a7f3694dbdf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "  Building wheel for warmup_scheduler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warmup_scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2967 sha256=b1f3ea56f9c001a8bb837d2f25306710c4a34a3a0fb3827b64d7333883d621cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/01/9e/d1820991c32916e9808c940f572b462f3e46427f3e76c4d852\n",
            "  Building wheel for typed-argument-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typed-argument-parser: filename=typed_argument_parser-1.10.0-py3-none-any.whl size=29724 sha256=e411a6fee3a6fdded5640c02199739247e42a0b78b520c1cb45b7f09fa586e30\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/90/25/3a703facea20e5495898c7afed250a145148e408f286e8fe80\n",
            "Successfully built efficientnet-pytorch pretrainedmodels warmup_scheduler typed-argument-parser\n",
            "Installing collected packages: warmup_scheduler, smmap, setproctitle, sentry-sdk, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, munch, lightning-utilities, einops, docker-pycreds, typing-inspect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitdb, typed-argument-parser, nvidia-cusolver-cu12, GitPython, wandb, torchmetrics, timesformer-pytorch, monai, efficientnet-pytorch, timm, pytorch-lightning, pretrainedmodels, segmentation_models_pytorch\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 efficientnet-pytorch-0.7.1 einops-0.7.0 gitdb-4.0.11 lightning-utilities-0.11.2 monai-1.3.0 munch-4.0.0 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pretrainedmodels-0.7.4 pytorch-lightning-2.0.9 segmentation_models_pytorch-0.3.3 sentry-sdk-1.45.0 setproctitle-1.3.3 smmap-5.0.1 timesformer-pytorch-0.4.1 timm-0.9.2 torchmetrics-1.3.2 typed-argument-parser-1.10.0 typing-inspect-0.9.0 wandb-0.16.6 warmup_scheduler-0.3\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **B. Training Only**"
      ],
      "metadata": {
        "id": "XVodaUBABa4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B.1. Select your training set**  \n",
        "If you are running training on the segments listed originally in A.4., nothing needs to be adjusted.\n",
        "\n",
        "***Scroll segments not listed:*** Otherwise, you will need to adjust **line 363** in *64x64_256stride_i3d.py* to match your training set. Add the numbers of the segments you need to the lists of numbers in this line, and remove the numbers you are not using. Adjust **line 100** to match your validation segment, if you have changed it from the default (20230820203112)."
      ],
      "metadata": {
        "id": "TTGGH_eBH9aJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B.2. Manually upload ink labels**\n",
        "  \n",
        "Upload the ink labels you intend to use into the folder with the following path: /content/gdrive/MyDrive/Vesuvius-Grandprize-Winner/all_labels/. It is easiest to do this directly in your google drive.\n",
        "\n",
        "Labels are included with the GP Winning model. Some updated labels can be found via the Discord [here](https://discord.com/channels/1079907749569237093/1208440488437350500)."
      ],
      "metadata": {
        "id": "-dsxEiBsB4Z3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46BoZVIGRL1h"
      },
      "source": [
        "**B.3. Propagate the ink labels into their respective folders**    \n",
        "\n",
        "Run the following script to place the ink labels into their correct folders on your google drive.\n",
        "\n",
        "***Scroll segments not listed:*** If you intend to run training on segments not listed in section A.4. above, you must adjust the script before propagating the ink labels. Add the segment numbers (which correspond to the directory folder names) to the lists in lines **27** and **41** of *prepare.py*.\n",
        "\n",
        "\n",
        "*Note*: If you are using the ink label provided with the Grand Prize winning model for segment 20231022170901, remove the # and space in front of lines **46, 47, 48**. It has special instructions as the file is .tif, not .png. You need not do this if the ink label for this segment is a .png from another source.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q78iu2e-VHPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5003addd-ea14-4c15-c81f-3dabdc67c945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20230702185753\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/Vesuvius-Grandprize-Winner/prepare.py\", line 63, in <module>\n",
            "    run_sanity_checks()\n",
            "  File \"/content/gdrive/MyDrive/Vesuvius-Grandprize-Winner/prepare.py\", line 43, in run_sanity_checks\n",
            "    assert os.path.exists(f'/content/gdrive/MyDrive/vesuvius_model/training/train_scrolls/{fragment_id}/layers/00.tif')\n",
            "AssertionError\n"
          ]
        }
      ],
      "source": [
        "!python prepare.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR2jB1xLTS9F"
      },
      "source": [
        "**B.4. Run Training**\n",
        "    \n",
        "Press the button and good luck!\n",
        "\n",
        "\n",
        "***wandb question:*** A wandb (Weights & Biases, an external data tracking and visualisation tool) question will appear after the data is loaded. Type 3 to continue to training without utilising this service.\n",
        "\n",
        "Your checkpoints after each epoch will be saved to the following directory: '/content/gdrive/mydrive/vesuvius_model/training/outputs. Training may take a *long* time.\n",
        "    \n",
        "***Potential Issues***\n",
        " *  *Not Enough RAM*: The RAM requirements for training are very large. If a ^C error appears while running the script, you'll need to reduce the size of the dataset.\n",
        "\n",
        " *  *Colab Timeouts*: Colab times out after 1.5 hours of inactivity, interrupting the script. Training will almost certainly take longer than this. You'll need to either interact with Colab every 1.5 hours to avoid this, or use another solution to click the screen automatically.\n",
        "\n",
        "*Note:* The script is currently set up to run on an A100 (40GB) with 83.5GB system RAM. If you are using different hardware you may need to adjust the number of workers (num_workers) and other settings in the script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrxCTSZbRrfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ac95d7-0642-4fd1-9c80-951d404d912c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set dataset path\n",
            "reading  20231005123336\n",
            "537.4818818569183 seconds taken to load images.\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python 64x64_256stride_i3d.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **C. Inference Only**"
      ],
      "metadata": {
        "id": "TGJpGJS9o2eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C.1. Select the segment to run inference on**\n",
        "\n",
        "If you are running training on the segment listed originally in A.4. (20231005123336), nothing needs to be adjusted.\n",
        "\n",
        "***Scroll segment not listed:*** Otherwise, you will need to adjust **line 28** of *inference_timesformer.py* to match the segment you selected."
      ],
      "metadata": {
        "id": "xhO7idQvGFZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C.2. Upload the checkpoint**\n",
        "\n",
        "Upload the checkpoint you wish to use to the /content/gdrive/MyDrive/vesuvius_model/checkpoints folder. The checkpoints used in the Grand Prize winning solution can be found [here](https://drive.google.com/drive/folders/1rn3GMOvtJRMBHOxVhWFVSY6IVI6xUnYp)."
      ],
      "metadata": {
        "id": "oZMQXSwuFU32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C.3. Adjust the script to match the checkpoint**\n",
        "\n",
        "Adjust **line 30** of *inference_timesformer.py* to match the checkpoint name. The default name is the checkpoint used in the Grand Prize winning solution."
      ],
      "metadata": {
        "id": "01MiDyKMNn1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***C.4 Free Colab Only:***\n",
        "\n",
        "*T4 GPU*: Adjust **line 77** of *inference_timesformer.py* to: num_workers = **2**"
      ],
      "metadata": {
        "id": "LeTvqHM4XXFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C.5. Run Inference**\n",
        "    \n",
        "Press the button and good luck!\n",
        "\n",
        "The results (predictions/images) will be saved in the /vesuvius_model/inference_output folder.  \n",
        "\n"
      ],
      "metadata": {
        "id": "6_2fCBtRT3cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_timesformer.py"
      ],
      "metadata": {
        "id": "xH6rM9LDq9fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **D. Contact**\n",
        "\n",
        "If you have any suggestions for improving this Colab or need help, please get in touch with polytrope. on Discord!"
      ],
      "metadata": {
        "id": "uNyJgspySLnV"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}